{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0f9b08d4ec9e1c02921960eaf1fee5318ba8fa976b60b01d5d81ab4a0f069da57",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display as ld\n",
    "\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "Reading CSV that contains audio file to instrument label mapping."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('instruments.csv')\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "Getting the distribution of recordings for each type of instrument"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_types = df['label'].value_counts()\n",
    "print(instrument_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = df['label'].unique()\n",
    "instruments"
   ]
  },
  {
   "source": [
    "System-wide configuration such as sampling rate."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    sr = 44100\n",
    "    random_state = 42"
   ]
  },
  {
   "source": [
    "Extracting a sample MFCC for each instrument type & plotting it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file):\n",
    "    signal, sr = librosa.load(file, Config.sr)\n",
    "    return librosa.feature.mfcc(y=signal, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = [extract_mfcc(f'wavfiles/{df[df.label == instrument].iloc[0,0]}') for instrument in instruments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=False,\n",
    "                             sharey=True, figsize=(20,5))\n",
    "fig.suptitle('Mel Frequency Cepstrum Coefficients', size=16)\n",
    "for i, instrument in enumerate(instruments):\n",
    "    row = 0 if i < 5 else 1\n",
    "    col = i % 5\n",
    "    axis = ax[row, col]\n",
    "    axis.set(title = f'{instrument}')\n",
    "    axis.get_xaxis().set_visible(False)\n",
    "    i = librosa.display.specshow(mfccs[i], x_axis='time', ax=ax[row, col])\n",
    "# plt.colorbar(i)"
   ]
  },
  {
   "source": [
    "Classifier class with ability to configure no. of samples and features used for classification.\n",
    "\n",
    "Internally uses Naive Bayes as the baseline followed by SVM for better performance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "class InstrumentClassifier:\n",
    "    def __init__(self, n_samples, features = ['mfcc']):\n",
    "        self.n_samples = n_samples\n",
    "        self.features = features\n",
    "\n",
    "        GNB = Pipeline([\n",
    "            ('Standard Scaler', StandardScaler()),\n",
    "            ('PCA', PCA(n_components = 10)),\n",
    "            ('Gaussian Naive Bayes', GaussianNB())\n",
    "        ])\n",
    "        SVC = Pipeline([\n",
    "            ('Standard Scaler', StandardScaler()),\n",
    "            ('PCA', PCA(n_components = 10)),\n",
    "            ('SVM', svm.SVC(gamma = 'auto'))\n",
    "        ])\n",
    "        self.pipe_dict = {0: 'GNB', 1: 'SVC'}\n",
    "        self.pipelines = [GNB, SVC]\n",
    "\n",
    "    def _extract_mfcc(self, signal, sr):\n",
    "        mfccs = librosa.feature.mfcc(y=signal, sr=sr)\n",
    "        aver = np.mean(mfccs, axis = 1)\n",
    "        feature = aver.reshape(20)\n",
    "        return feature\n",
    "\n",
    "    def _extract_melspectrogram(self, signal, sr):\n",
    "        spectrogram = librosa.feature.melspectrogram(signal)\n",
    "        spectrogram = librosa.power_to_db(spectrogram)\n",
    "        spectrogram = spectrogram.astype(np.float32)\n",
    "        spectrogram = np.mean(spectrogram, axis=1)\n",
    "        return spectrogram\n",
    "\n",
    "    def _extract(self, row):\n",
    "        signal, sr = librosa.load(f'wavfiles/{row[0]}', Config.sr)\n",
    "        if 'mfcc' in self.features:\n",
    "            X = self._extract_mfcc(signal, sr)\n",
    "        if 'melspectrogram' in self.features:\n",
    "            X = self._extract_melspectrogram(signal, sr)\n",
    "        X_y = np.append(X, row[1])\n",
    "        return X_y\n",
    "\n",
    "    def _extract_X_y(self, df):\n",
    "        samples = df.sample(n=self.n_samples, replace=True, random_state=Config.random_state)\n",
    "        data = samples.apply(self._extract, axis=1, result_type='expand')\n",
    "        X = data.iloc[:,:-1]\n",
    "        y = data.iloc[:,-1]\n",
    "        return X, y\n",
    "\n",
    "    def extract_features(self, df):\n",
    "        self.X, self.y = self._extract_X_y(df)\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.25, random_state=Config.random_state)\n",
    "\n",
    "    def fit(self):\n",
    "        for p in self.pipelines:\n",
    "            p.fit(self.x_train, self.y_train)\n",
    "    \n",
    "    def perf(self):\n",
    "        print(f'n_samples:{self.n_samples}, features: {self.features}')\n",
    "        for i,model in enumerate(self.pipelines):\n",
    "            print('{} Accuracy: {}'.format(self.pipe_dict[i], model.score(self.x_test, self.y_test)))\n",
    "            print(f'Cross-validation result: {cross_validate(model, self.X, self.y)[\"test_score\"]}')\n"
   ]
  },
  {
   "source": [
    "Testing the classifier with different audio features & sample sizes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['mfcc', 'melspectrogram']:\n",
    "    for samples in [128, 256, 512]:\n",
    "        classifier = InstrumentClassifier(samples, [feature])\n",
    "        classifier.extract_features(df)\n",
    "        classifier.fit()\n",
    "        classifier.perf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}